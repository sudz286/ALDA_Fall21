# -*- coding: utf-8 -*-
"""HW4_5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xZrAUbb7HIT_5K5yNNOKKhQn15TgU7hL
"""

import pandas as pd

df = pd.read_csv('svm_2021.csv')

df.head()

df['Class'].value_counts()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'Class'],df['Class'],stratify = df['Class'],train_size = 0.8)

print("Number of Class 0 and Class 1 samples in training data")
print(y_train.value_counts())

print("Number of Class 0 and Class 1 samples in testing data")
print(y_test.value_counts())

train_svm = pd.read_csv('train_data_2021.csv')
test_svm = pd.read_csv('test_data_2021.csv')
train_svm.head()

from sklearn.svm import SVC
C = [0.1, 0.2, 0.3, 0.5, 1, 2, 3, 5, 10]
models = []

for c in C:
  model = SVC(C = c,kernel = 'linear')
  models.append(model.fit(train_svm.loc[:,df.columns != 'Class'],train_svm['Class']))

sv_count = []
for m in models:
  sv_count.append(m.n_support_[0] + m.n_support_[1])
import matplotlib.pyplot as plt
plt.plot(C,sv_count)
plt.xlabel("C")
plt.ylabel("Support Vectors")
plt.scatter(C,sv_count)
plt.show()

# As C increases, the number of support vectors decreases since the classifier uses hyperplanes that misclassfies lesser points at the expense of a using a smaller margin.
# When C decreases, the number of support vectors increases since the classifier uses hyperplanes that has a larger margin at the expense of misclassifying more points.
# In short, it is a tradeoff between margin-size and number of misclassified points.

from sklearn.model_selection import GridSearchCV

C = [0.1, 0.2, 0.3, 1, 5, 10, 20, 100, 200, 1000]
degree = [1, 2, 3, 4, 5]
coef0 = [0.0001, 0.001, 0.002, 0.01, 0.02, 0.1, 0.2, 0.3, 1, 2, 5, 10]
gamma = [0.0001, 0.001, 0.002, 0.01, 0.02, 0.03, 0.1, 0.2, 1, 2, 3]
kernel = ['linear', 'rbf', 'poly','sigmoid']

svc = SVC()

parameter_linear = {'kernel': [kernel[0]],'C': C}
clf = GridSearchCV(svc,parameter_linear, cv = 5, refit = 'accuracy')
clf.fit(train_svm.loc[:, train_svm.columns != 'Class'], train_svm['Class'])
y_linear = clf.predict(test_svm.loc[:,train_svm.columns != 'Class'])

parameter_poly = {'kernel' : [kernel[2]], 'C': C,'degree': degree, 'coef0': coef0}
clf2 = GridSearchCV(svc,parameter_poly, cv = 5, refit = 'acuracy')
clf2.fit(train_svm.loc[:, train_svm.columns != 'Class'], train_svm['Class'])
y_poly = clf2.predict(test_svm.loc[:,test_svm.columns != 'Class'])

parameter_rbf = {'kernel' : [kernel[1]], 'C': C,'gamma':gamma}
clf3 = GridSearchCV(svc,parameter_rbf, cv = 5, refit = 'accuracy')
clf3.fit(train_svm.loc[:, train_svm.columns != 'Class'], train_svm['Class'])
y_rbf = clf3.predict(test_svm.loc[:,test_svm.columns != 'Class'])

parameter_sigmoid = {'kernel' : [kernel[3]], 'C': C,'gamma':gamma, 'coef0': coef0}
clf4 = GridSearchCV(svc,parameter_sigmoid, cv = 5, refit = 'accuracy')
clf4.fit(train_svm.loc[:, train_svm.columns != 'Class'], train_svm['Class'])
y_sigmoid = clf4.predict(test_svm.loc[:,test_svm.columns != 'Class'])

# Accuracy, Precision, Recall, F-measure

from sklearn import metrics 

print("\tAcc  f1\t\t\tPrecision\t   Recall\t      C deg c0 gamma")
print("---------------------------------------------------------------------------------------------")
print( "Linear ",metrics.accuracy_score(test_svm['Class'],y_linear), metrics.f1_score(test_svm['Class'], y_linear), metrics.precision_score(test_svm['Class'], y_linear),metrics.recall_score(test_svm['Class'], y_linear),clf.best_estimator_.C, clf.best_estimator_.degree, clf.best_estimator_.coef0, "-")
print( "Poly   ", metrics.accuracy_score(test_svm['Class'], y_poly), metrics.f1_score(test_svm['Class'], y_poly),"", metrics.precision_score(test_svm['Class'], y_poly),"",metrics.recall_score(test_svm['Class'], y_poly),clf2.best_estimator_.C, clf2.best_estimator_.degree, clf2.best_estimator_.coef0, "-")
print( "RBF    ", metrics.accuracy_score(test_svm['Class'],y_rbf), metrics.f1_score(test_svm['Class'],y_rbf), metrics.precision_score(test_svm['Class'],y_rbf),metrics.recall_score(test_svm['Class'],y_rbf),clf3.best_estimator_.C,'', clf3.best_estimator_.degree, clf3.best_estimator_.coef0, clf3.best_estimator_.gamma )
print( "Sigmoid",metrics.accuracy_score(test_svm['Class'],y_sigmoid), metrics.f1_score(test_svm['Class'],y_sigmoid), metrics.precision_score(test_svm['Class'],y_sigmoid),metrics.recall_score(test_svm['Class'],y_sigmoid),clf4.best_estimator_.C,'', clf4.best_estimator_.degree, clf4.best_estimator_.coef0, clf4.best_estimator_.gamma)

print(clf.best_estimator_.C, clf.best_estimator_.degree, clf.best_estimator_.coef0, clf.best_estimator_.gamma)
print(clf2.best_estimator_.C, clf2.best_estimator_.degree, clf2.best_estimator_.coef0, clf2.best_estimator_.gamma)
print(clf3.best_estimator_.C, clf3.best_estimator_.degree, clf3.best_estimator_.coef0, clf3.best_estimator_.gamma)
print(clf4.best_estimator_.C, clf4.best_estimator_.degree, clf4.best_estimator_.coef0, clf4.best_estimator_.gamma)





